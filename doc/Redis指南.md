 # 引言
本文围绕以下几点进行阐述  
1. 为什么使用redis
2. 使用redis有什么缺点
3. 单线程的redis为什么这么快
4. redis的数据类型，以及每种数据类型的使用场景
5. redis的过期策略以及内存淘汰机制
6. redis和数据库双写一致性问题
7. 如何应对缓存穿透、缓存雪崩以及缓存击穿问题

# 链接
- [Redis 命令参考](http://doc.redisfans.com/)

# 正文
## 为什么使用redis
得在项目中使用redis，主要是从两个角度去考虑：**性能**和**并发**。  

- 性能：  
如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。  
![](https://img-blog.csdn.net/20180531085918614)

- 并发：  
在并发访问服务器的情况下，所有的请求直接访问数据库，数据库的操作可能会极其缓慢，甚至是宕机。为了避免这种此类问题，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。

## 使用redis有什么缺点

1. 缓存和数据库双写一致性问题
2. 缓存雪崩问题
3. 缓存击穿问题
4. 缓存的并发竞争问题

这四个问题，我个人是觉得在项目中，比较常遇见的，具体解决方案，后文给出。


## 单线程的redis为什么这么快

1. 纯内存操作
2. 单线程操作，避免了频繁的上下文切换
3. 采用了非阻塞I/O多路复用机制


题外话：我们现在要仔细的说一说I/O多路复用机制，因为这个说法实在是太通俗了，通俗到一般人都不懂是什么意思。  
![I/O多路复用机制](https://img-blog.csdn.net/20180531085855659)  
参照上图，简单来说，就是。我们的redis-client在操作的时候，会产生具有不同事件类型的socket。在服务端，有一段I/0多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。  
需要说明的是，这个I/O多路复用机制，redis还提供了select、epoll、evport、kqueue等多路复用函数库，大家可以自行去了解。


## redis的数据类型，以及每种数据类型的使用场景

- string  
常规的操作有set/get，value可以是string也可以是数字，可通key设置过期时间。一般做一些复杂的计数功能的缓存。

- hash  
hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。

- list  
使用list的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。LIST可以很好的完成排队，先进先出的原则。

- set  
因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。

- sorted set  
sorted set多了一个权重参数score,集合中的元素能够按score进行排列。


##  redis的过期策略以及内存淘汰机制

**分析**:  
这个问题其实相当重要，到底redis有没用到家，这个问题就可以看出来。比如你redis只能存5G数据，可是你写了10G，那会删5G的数据。怎么删的，这个问题思考过么？还有，你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高，有思考过原因么?
**回答**:  
redis采用的是 **定期删除+惰性删除**策略。

**为什么不用定时删除策略?**  
定时删除通过用一个定时器来负责监视key，过期则自动删除。虽然内存及时释放，但是**十分消耗CPU资源**。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key，因此没有采用这一策略。  

**定期删除+惰性删除是如何工作的呢?**  
定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。  
于是，惰性删除派上用场。在你获取某个key的时候，redis会检查这个key否过期？过期则此时就会删除它。

**采用定期删除+惰性删除就没其他问题了么?**  
不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用**内存淘汰机制**。

在redis.conf中有一行配置，该配置是设置内存淘汰策略的(什么，你没配过？好好反省一下自己)
~~~
 maxmemory-policy volatile-lru
~~~
- noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。

- allkeys-lru（推荐使用）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。

- allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。

- volatile-lru（不推荐）：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把redis既当缓存，又做持久化存储的时候才用。

- volatile-random（不推荐）：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
- volatile-ttl（不推荐）：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。


## redis和数据库双写一致性问题
**分析**：一致性问题是分布式常见问题，还可以再分为**最终一致性**和**强一致性**。数据库和缓存双写，就必然会存在不一致的问题。  
答这个问题，先明白一个前提，如果对数据有强一致性要求，则不能放缓存。我们所能做的，只能是保证最终一致性。另外，我们所做的方案其实从根本上来说，只能说降低不一致发生的概率，无法完全避免。  
**回答**：首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。

## 如何应对缓存穿透、缓存雪崩以及缓存击穿问题

**分析**：这两个问题，说句实在话，一般中小型传统软件企业，很难碰到这个问题。如果有大并发的项目，流量有几百万左右。这两个问题一定要深刻考虑。  

### 缓存穿透  
是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。

**解决方案：**
- 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。

- 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。

- 供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。

### 缓存雪崩
是指在设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，导致所有的查询都落在数据库上，造成了缓存雪崩。

**解决方案：**

- 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。

- 可以通过缓存reload机制，预先去更新缓存，在即将发生大并发访问前手动触发加载缓存。

- 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。

- 做二级缓存，或者双缓存策略。A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期。

### 缓存击穿
对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。   
缓存在某个时间点过期的时候，恰好在这个时间点对这个key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端db加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端db压垮。

**解决方案：**  
与解决缓存雪崩的方案一致。
